{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8223b9",
   "metadata": {},
   "source": [
    "<h1><center>Back Propagation in Neural Networks</center></h1>\n",
    "<h3><center>Reading time: 20 minutes</center></h3>\n",
    "<h4><center>Author: Nikolas Achatz</center></h4>\n",
    "\n",
    "In this notebook we will learn how to finish training a neural network using back propagation. We will take our forward implementation from the previous notebook and add in back propagation. Firstly, we will go through the theory and mathematics to allow for us to back propagate. Secondly, we will code the entire process of back propagation by adding to our current setup and then we will train on a basic XOR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca36982",
   "metadata": {},
   "source": [
    "![Example of a neural network](./Images/neuralnetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d178f21b",
   "metadata": {},
   "source": [
    "Here is the neural network we have been working with. We have two inputs going into 1 hidden layer with 2 neurons and outputting to one neuron. The steps of forward propagation simply just make a prediction by calculating the output through layers of neurons. However, at the start if we recall we randomly initialize our weights and biases. Obviously, we can expect the output of this neural network to be nonsense, but using back propagation we can update these and take a step in the direction of better predictions. Let's use the following dataset as a running example for this notebook: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd32e7",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-color:#93a1a1;border-spacing:0;}\n",
    ".tg td{background-color:#fdf6e3;border-color:#93a1a1;border-style:solid;border-width:1px;color:#002b36;\n",
    "  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{background-color:#657b83;border-color:#93a1a1;border-style:solid;border-width:1px;color:#fdf6e3;\n",
    "  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-qr91{border-color:inherit;font-family:\"Arial Black\", Gadget, sans-serif !important;;font-size:22px;font-weight:bold;\n",
    "  text-align:left;vertical-align:top}\n",
    ".tg .tg-4arq{font-family:\"Arial Black\", Gadget, sans-serif !important;;font-size:22px;font-weight:bold;text-align:left;\n",
    "  vertical-align:top}\n",
    ".tg .tg-em9h{font-family:\"Arial Black\", Gadget, sans-serif !important;;font-size:22px;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-qr91\">A</th>\n",
    "    <th class=\"tg-4arq\">B<br></th>\n",
    "    <th class=\"tg-4arq\">Y</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-em9h\">0</td>\n",
    "    <td class=\"tg-em9h\">0<br></td>\n",
    "    <td class=\"tg-em9h\">0<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-em9h\">0</td>\n",
    "    <td class=\"tg-em9h\">1</td>\n",
    "    <td class=\"tg-em9h\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-em9h\">1</td>\n",
    "    <td class=\"tg-em9h\">0</td>\n",
    "    <td class=\"tg-em9h\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-em9h\">1</td>\n",
    "    <td class=\"tg-em9h\">1</td>\n",
    "    <td class=\"tg-em9h\">0</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa2fda",
   "metadata": {},
   "source": [
    "If this looks familiar, it's just a simple XOR gate. The idea is once we are done here our model will predict the correct values in the Y column based off of the A,B inputs. Let's first show that this does not work as is. This code is imported from our first notebook and we will run it with this dataset so we can compare before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a29e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Each layer in our neural network\n",
    "class NeuralLayer:\n",
    "    # Randomly initialize weights and biases based off of layer size\n",
    "    def __init__(self, input_neurons, output_neurons):\n",
    "        self.weights = np.random.randn(input_neurons, output_neurons)\n",
    "        self.bias = np.zeros((1,output_neurons))\n",
    "\n",
    "    # Two different activations, sigmoid by default\n",
    "    def sigmoid(self, neurons):\n",
    "        return 1.0/(1.0 + np.exp(-neurons))\n",
    "    \n",
    "    def relu(self, neurons):\n",
    "        return neuron * (neurons > 0)\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, input, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            return self.sigmoid(input @ self.weights + self.bias)\n",
    "        else:\n",
    "            return self.relu(input @ self.weights + self.bias)\n",
    "\n",
    "\n",
    "# Our neural net\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # Dynamically create all layers \n",
    "    def __init__(self, input_neurons, hidden_neurons, layer_count, output_neurons = 1):\n",
    "        \n",
    "        # Used to ensure input neurons match inputted data\n",
    "        self.neuron_safety = input_neurons\n",
    "        \n",
    "        # Assert we have a input and output layer at the least\n",
    "        assert layer_count >= 2 and output_neurons >= 1\n",
    "        \n",
    "        # Input layer\n",
    "        self.layers = [NeuralLayer(input_neurons, hidden_neurons)]\n",
    "                \n",
    "        # Hidden Layers\n",
    "        for i in range(layer_count - 2):\n",
    "            self.layers.append(NeuralLayer(hidden_neurons, hidden_neurons))\n",
    "            \n",
    "        # Output layer\n",
    "        self.layers.append(NeuralLayer(hidden_neurons, output_neurons))\n",
    "    \n",
    "    # Forward pass for each layer\n",
    "    def forward(self, inp, activation = 'sigmoid'):\n",
    "        \n",
    "        assert inp.shape[0] == self.neuron_safety\n",
    "        \n",
    "        \n",
    "        for layer in self.layers:\n",
    "            inp = layer.forward(inp, activation)\n",
    "            \n",
    "        return inp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498bd13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted: [[0.34648805]] | actual value: 0 \n",
      "Model predicted: [[0.18438426]] | actual value: 1 \n",
      "Model predicted: [[0.34095914]] | actual value: 1 \n",
      "Model predicted: [[0.20900606]] | actual value: 0 \n"
     ]
    }
   ],
   "source": [
    "# Create a neural network with 2 inputs, 6 hidden neurons in each layer, and 5 layers \n",
    "net = NeuralNetwork(2,6,2)\n",
    "\n",
    "# Input data (A,B)\n",
    "X = np.array(([0,0],[0,1],[1,0],[1,1]))\n",
    "\n",
    "# Expected output data \n",
    "Y = np.array([0,1,1,0])\n",
    "\n",
    "for idx, prediction in enumerate(X):\n",
    "    prediction = net.forward(prediction)\n",
    "    print(\"Model predicted: {} | actual value: {} \".format(prediction, Y[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc58ad",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><h2><center>Measuring Loss</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e6e33",
   "metadata": {},
   "source": [
    "Clearly, we see that our model is predicting junk. This makes perfect sense since the weights of our neural network are randomly initialized. Let's start to figure out how to adjust the weights so we can train our neural network.\n",
    "\n",
    "\n",
    "Firstly, we need to figure out a way to quantify our loss on our prediction. To do this we need a loss function. A loss function is simply just a way of measuring loss by looking at a datapoints true and predicted value. Let's take mean squared error as our loss function. MSE is a very common loss function for regression, we are going to use it in this derivation of back propagation due to it's simplicity, however when we implement we will be using Binary Cross Entropy for binary predictions (1 or 0). \n",
    "\n",
    "$$L = MSE = \\frac{1}{n}\\sum(Y^{predicted}_i - Y^{true}_i)^2$$\n",
    "\n",
    "\n",
    "Simply, this means we take the average of all of our predicted values loss squared. For example, above we predicted 0.588 for [0,0]. The actual value we want is 0, thus we take the loss to be $(0.588 - 0)^2$ for this point. Now we can take the sum and average of all the other output neurons if we want to finish calculating our loss for the general case. In our scenario, we are using one output neuron so our measurement of error will simply be $$(Y^{predicted}_i - Y^{true}_i)^2$$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23041f11",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><h2><center>Gradient Descent - Minimizing the loss</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce73aa",
   "metadata": {},
   "source": [
    "Gradient descent seeks to minimize this loss function or in other words, the error. This is done by descending down the cost function.\n",
    "\n",
    "![Example of a neural network](./Images/gradDescent.png)\n",
    "\n",
    "Looking at this example we can see that we slowly take steps to the minimum of the loss functions slope. In other words, this means we need to look at the derivative (in the 1D case) of the cost function - normally this is refered to as the gradient. The problem we run into is that we only have the predictions and the labels in our loss functions derivative. Moreso, we want to adjust our predictions, but what actually makes our predictions? If we recall, the predictions are calculated through forward propagation using weights and biases. Therefore, in back propagation and gradient descent we seek to update these weights and biases to minimize the loss function. Clearly, the derivative of the loss function doesn't do that by itself. However, this is the first step of our gradient descent algorithm, we need to take the derivative (gradient) of the loss function with respect to our predictions.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial Y^{p}} = 2*(Y^{predicted} - Y^{true})$$\n",
    "\n",
    "\n",
    "Hopefully it's clear why we are using the MSE for the loss function here as this partial derivative is trivial (or should be).\n",
    "\n",
    "\n",
    "Next we should look at how changes in weights change our predictions. Moreso, how does changing weights change our activations or outputs? Well similarly we can take the partial derivative with respect to weights of our activation function. If we remember, we used sigmoid as our activation function.\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c259b",
   "metadata": {},
   "source": [
    "<center><h2>$Sigmoid = \\frac{1}{1+e^{-w}}$</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b38ced",
   "metadata": {},
   "source": [
    "The partial derivative of this is \n",
    "$$ \\frac{1}{1+e^{-w}}*(1-\\frac{1}{1+e^{-w}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa0f40",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><h2><center>Chain Rule</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb3e941",
   "metadata": {},
   "source": [
    "This is a good point in time to take a step back and remind ourselves of the chain rule of differentiation. This is simply the idea that the derivation of a function embedded with another function is just the derivative of the two functions independently multiplied. \n",
    "\n",
    "$$ \\frac{\\partial}{\\partial x}f(g(x)) =  g^`(x)*f^`(x)$$\n",
    "\n",
    "Why is this important to us? Well, to do back propagation we are continuously going to be taking the partial derivative for each layer. This means when we are calculating our gradients we can simply take the gradient for the next layer and simply multiply it to the previous layers. EX: The first layer we do back propagation on may look like: \n",
    "\n",
    "$$ \\frac{\\partial}{\\partial x}f(g(x))$$\n",
    "\n",
    "The next layer in the sequence will simply be:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial x}f(g(h(x)))$$\n",
    "\n",
    "Making it very easy for us to continuously calculate our gradients for each layer we back propagate through!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa9b6e",
   "metadata": {},
   "source": [
    "<h2><center>Gradient Descent - Minimizing the loss w/ Chain Rule</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576d579",
   "metadata": {},
   "source": [
    "Now that we understand the chain rule and our derivatives (gradients) of the loss function and the activation function we can begin to understand how to minimize the loss function. Well again the only thing that needs to change here is the weights and the bias for each neurons. Therefore, we need to find the rate of change of the loss function with respect to the weights and biases of our layers.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = ?$$\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Let's simplify this, since this can get very messy. Let's look at the simplified case:\n",
    "\n",
    "![Example of a neural network](./Images/backprop1.png)\n",
    "\n",
    "\n",
    "\n",
    "Let's look at the relationship between our error and our second set of weights. The W2 is an input to our preactivation which is in input to our activation which is then an input to our loss function. This is how we can use the chain rule derived above as these are embedded functions. Therefore we know that the loss with respect to weights is just the product of these 3 partial derivatives:\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<center><b>\n",
    "a: activation,\n",
    "p: preactivation,\n",
    "L: loss,\n",
    "w2: second set of weights, and\n",
    "w1: first set of weights\n",
    "    </b>\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w2} = \\frac{\\partial L}{\\partial a}\\frac{\\partial a}{\\partial p}\\frac{\\partial p}{\\partial w}$$\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Now what exactly are these derivatives? $\\frac{\\partial L}{\\partial a}$ is simply the gradient of our loss function with respect to our predictions - shown above.\n",
    "\n",
    "\n",
    "$\\frac{\\partial a}{\\partial p}$ is just the gradient of our activation function, also shown above.\n",
    "\n",
    "Lastly, $\\frac{\\partial p}{\\partial w}$ is just the gradient of our preactivation with respect to weights, which clear is just the inputs since preactivation is simply a weighted sum of inputs. $i*w + b$ => $i$\n",
    "\n",
    "![Example of a neural network](./Images/backprop2.png)\n",
    "\n",
    "\n",
    "Perfect, we now have related our cost function to our weights for the last layer and can start to actually update them. Before we learn how to use this to update our weights for the last layer, what about other layers? To continue backpropagation we simply keep modeling these as inputs to other functions. Instead of taking the partial derivative of the inputs with respect to the weights we will just continue to the previous layers activation.\n",
    "\n",
    "![Example of a neural network](./Images/backprop3.png)\n",
    "\n",
    "\n",
    "Therefore, we can model the relationship for W1 as: \n",
    "$$\\frac{\\partial L}{\\partial w1} = \\frac{\\partial L}{\\partial a^{-1}}\\frac{\\partial a^{-1}}{\\partial p^{-1}}\\frac{\\partial p^{-1}}{\\partial a}\\frac{\\partial a}{\\partial p}\\frac{\\partial p}{\\partial w1}$$\n",
    "\n",
    "Where the -1 super script refers to the previous layer.\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a70f0",
   "metadata": {},
   "source": [
    "<h2><center>Gradient Descent - Learning Rate</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515771e8",
   "metadata": {},
   "source": [
    "Next we need to define learning rate. This is simply the adjustment of magnitude of our error. Meaning this determines how big of a step we take towards the minimum of our cost function. It's important this is small so we don't overshoot or cause what's called a \"exploding\" gradient. This is generally set between 0.00001 and 0.1. We utilize this by multipling our loss function with respect to the weights with this learning rate.\n",
    "\n",
    "<br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50c523",
   "metadata": {},
   "source": [
    "<h2><center>Gradient Descent - Adjustment</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c93af5",
   "metadata": {},
   "source": [
    "Finally, we need to actually adjust the weights for each layer in the neural network. The first hidden layer we have already derived\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w2} = \\frac{\\partial L}{\\partial a}\\frac{\\partial a}{\\partial p}\\frac{\\partial p}{\\partial w}$$\n",
    "More importantly, we have to include the learning rate\n",
    "\n",
    "$$0.01 * \\frac{\\partial L}{\\partial a}\\frac{\\partial a}{\\partial p}\\frac{\\partial p}{\\partial w}$$\n",
    "\n",
    "\n",
    "Finally, for the actual adjustment we will take the weights of the layer we are in and take away this product to yield our new weights.\n",
    "\n",
    "$$Updated = current - 0.01 * \\frac{\\partial L}{\\partial a}\\frac{\\partial a}{\\partial p}\\frac{\\partial p}{\\partial w}$$\n",
    "\n",
    "\n",
    "Voila! We derived backpropagation for one hidden layer. For our second layer and so on: \n",
    "\n",
    "$$Updated = current - 0.01 * \\frac{\\partial L}{\\partial a^{-1}}\\frac{\\partial a^{-1}}{\\partial p^{-1}}\\frac{\\partial p^{-1}}{\\partial a}\\frac{\\partial a}{\\partial p}\\frac{\\partial p}{\\partial w1}$$\n",
    "\n",
    "<br/><br/><br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d4560",
   "metadata": {},
   "source": [
    "<h2><center>Gradient Descent - Simplified</center></h2>\n",
    "\n",
    "\n",
    "This can be complicated, but let's simplify it. All we need to do is start by taking the gradient of our loss function at the end of our forward pass (whatever it may be), in this case MSE:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a} = 2*(preds - labels)$$\n",
    "\n",
    "Next all we need is the gradient of our activation (whatever it may be), in this case sigmoid:\n",
    "\n",
    "$$\\frac{\\partial a}{\\partial p} = \\frac{1}{1+e^{-w}}*(1-\\frac{1}{1+e^{-w}})$$\n",
    "\n",
    "\n",
    "Truly, this is all we need to do our back propagation now. We will set our initial gradient variable to the MSE gradient and multiply it against the activation gradient. Now for each layer we will take that product and multiply against the inputs and the weights independently and save the outcomes. The product of our gradients with the inputs of this layer will be the adjustment we will make to this layer, the product with the current weights will be sent to the next layer as per our equation above.\n",
    "\n",
    "<br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ed231",
   "metadata": {},
   "source": [
    "<h2><center>Code</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a06afc",
   "metadata": {},
   "source": [
    "As we saw above, the model currently predicts junk. This mean we need to implement back propagation, this starts with a loss function. For the example above we used MSE for simplicity, however this isn't the greatest loss function for binary prediction. A good choice of loss function is binary cross entropy, but don't worry the same methods apply. We will simply take binary cross entropy gradient and use that in replacement of MSE gradient. For sanity, we will implement both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5620134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSquaredError(self, preds, labels):\n",
    "    return  (self.preds - self.labels)**2\n",
    "\n",
    "def meanSquaredErrorGrad(self):\n",
    "    return 2 * (self.preds - self.labels)\n",
    "\n",
    "def binaryCrossError(self, preds, labels):\n",
    "    return -labels*np.log(preds) + (1 - labels)*np.log(1-preds)\n",
    "\n",
    "def binaryCrossErrorGrad(self):\n",
    "    return -1* ((self.labels / self.preds) - (1-self.labels) / (1-self.preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545face",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "Remember since we only have 1 output neuron we are not taking the average as you would in traditional MSE! This means we can simply implement this as shown up. \n",
    "\n",
    "We used sigmoid and as such we need the derivative of our activation function implemented as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23827b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidBackward(self, grad):\n",
    "    return grad * self.act * (1 - self.act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f54d5b",
   "metadata": {},
   "source": [
    "<br/><br/>Next we need a function that takes step of gradient descent for us using our learning rate. Remember this is just current weights minus the old weights deducted by the partial derivatives multiplied to the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc494afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, step_size):\n",
    "    self.weights -= step_size*self.grad_weights\n",
    "    self.bias -= step_size*self.grad_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393d2a4",
   "metadata": {},
   "source": [
    "<br/><br/>Finally, we need to implement back propagation. We will do this per layer so it will go in our Neural Layer class. Let's think about this, first we need the gradient of our loss function, then we multiply it to the gradient activation of our layer. Finally, we multiply against the inputs of that layer. This yields the adjustment we need to make to this layer. However, we can't end the function at that point we need to now be able to backpropagate to the next layer. The next part of this derivation is simply taking the value of the gradient of the loss function multiplied to the gradient of the activation and multiply it to the weights of this layer and send it back. From there was can rinse and repeat to update weights for the entire network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac89172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass for this layer\n",
    "def backward(self, grad):\n",
    "    # Take the current gradient and multiply against the layers gradient activation\n",
    "    grad = self.sigmoidBackward(np.atleast_2d(grad))\n",
    "\n",
    "    # The adjustment is the gradient multiplied to that layers inputs\n",
    "    self.grad_weights = np.matmul(self.input.T, grad)\n",
    "    \n",
    "    # The bias is simply a sum of gradients\n",
    "    self.grad_bias = grad.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    # Return the partial derivative with respect to the preactivation\n",
    "    return grad @ self.weights.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa481d6",
   "metadata": {},
   "source": [
    "<br/><br/>Finally, lets put these functions in our previously developed code. Error will be evaluated at the end so it belongs in the NeuralNetwork class. All of the backward propagation steps will be in the NeuralLayer as we will compute at each layer independently. More so, we need a function that will run each layers back propagation which is simply called the backward function on each layer from back to front. After that we need each layer to take a step so we can simply implement a step function which does the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44bb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Each layer in our neural network\n",
    "class NeuralLayer:\n",
    "    def __init__(self, input_neurons, output_neurons):\n",
    "        self.weights = np.random.randn(input_neurons, output_neurons)* np.sqrt(2. / input_neurons)\n",
    "        self.bias = np.ones((1,output_neurons)) * 0.5\n",
    "\n",
    "    def sigmoid(self, neurons):\n",
    "        self.act = 1.0/(1.0 + np.exp(-neurons))\n",
    "        return self.act\n",
    "    \n",
    "    # ADDED - activation gradient\n",
    "    def sigmoidBackward(self, grad):\n",
    "        return grad * self.act * (1 - self.act)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = np.atleast_2d(input)\n",
    "        return self.sigmoid(input @ self.weights + self.bias)\n",
    "        \n",
    "    # ADDED - backward pass for this layer\n",
    "    def backward(self, grad):\n",
    "        \n",
    "        grad = self.sigmoidBackward(np.atleast_2d(grad))\n",
    "            \n",
    "        self.grad_weights = np.matmul(self.input.T, grad)\n",
    "        self.grad_bias = grad.sum(axis=0, keepdims=True)\n",
    "        return grad @ self.weights.T\n",
    "    \n",
    "    # ADDED - adjust weights\n",
    "    def step(self, step_size):\n",
    "        self.weights -= step_size*self.grad_weights\n",
    "        self.bias -= step_size*self.grad_bias\n",
    "\n",
    "# Our neural net\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # Dynamically create all layers \n",
    "    def __init__(self, input_neurons, hidden_neurons, layer_count, output_neurons = 1):\n",
    "                \n",
    "        # Used to ensure input neurons match inputted data\n",
    "        self.neuron_safety = input_neurons\n",
    "        assert layer_count >= 2 and output_neurons >= 1\n",
    "        \n",
    "        # Input layer\n",
    "        self.layers = [NeuralLayer(input_neurons, hidden_neurons)]\n",
    "                \n",
    "        # Hidden Layers\n",
    "        for i in range(layer_count - 2):\n",
    "            self.layers.append(NeuralLayer(hidden_neurons, hidden_neurons))\n",
    "            \n",
    "        # Output layer\n",
    "        self.layers.append(NeuralLayer(hidden_neurons, output_neurons))\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        assert inp.shape[0] == self.neuron_safety\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            inp = layer.forward(inp)\n",
    "            \n",
    "        return inp \n",
    "    \n",
    "    # ADDED - for each layer in the neural net back propagate\n",
    "    def backward(self, grad):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "            \n",
    "    # ADDED - when done adjust weights for each layer\n",
    "    def step(self, step_size = 0.01):\n",
    "        for layer in self.layers:\n",
    "            layer.step(step_size)\n",
    "    \n",
    "    # ADDED - MSE\n",
    "    def meanSquaredError(self, preds, labels):\n",
    "        self.labels = labels\n",
    "        self.preds = preds\n",
    "        return  (self.preds - self.labels)**2\n",
    "    \n",
    "    # ADDED - MSE gradient  \n",
    "    def meanSquaredErrorGrad(self):\n",
    "        return 2 * (self.preds - self.labels)\n",
    "        \n",
    "    # ADDED - Binary cross entropy\n",
    "    def Error(self, preds, labels):\n",
    "        self.preds = preds\n",
    "        self.labels = labels\n",
    "        return -labels*np.log(preds) + (1 - labels)*np.log(1-preds)\n",
    "    \n",
    "    # ADDED - Binary cross entropy gradient\n",
    "    def ErrorGrad(self):\n",
    "        return -1* ((self.labels / self.preds) - (1-self.labels) / (1-self.preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b7ccf9",
   "metadata": {},
   "source": [
    "<br/><br/>Great! Let's evaluate our model. Let's create a neural network with 2 inputs, 16 hidden neurons, and 4 layers. We will train on the XOR dataset above and see the difference. An epoch is simply how many times we will train each 4 data points. We will train for 50,000 epochs going through each datapoint making predictions off of it then back propagating to minimize the loss and take a step to adjust the weights for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19550108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted: [0.0033990771655392662, 0.5038756910441456, 0.9955799136303164, 0.4969624186014994]\n",
      "actual values: [[0 0 1 1]] \n",
      "Model predicted: [0, 1, 1, 0]\n",
      "actual values: [[0 0 1 1]] \n"
     ]
    }
   ],
   "source": [
    "# Create a neural network with 2 inputs, 2 hidden neurons in each layer, and 2 layers \n",
    "net = NeuralNetwork(2,2,2)\n",
    "epochs = 50000\n",
    "\n",
    "# Input data (A,B) for XOR\n",
    "X = np.array([[0,0],[1,1], [1,0],[0,1]])\n",
    "\n",
    "# Expected output data \n",
    "Y = np.array([[0],[0],[1],[1]])\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    preds = []\n",
    "    for idx, x in enumerate(X):\n",
    "        predictions = net.forward(x)\n",
    "        preds.append(float(predictions))\n",
    "        loss = net.Error(predictions, Y[idx])\n",
    "        loss_grad = net.ErrorGrad()\n",
    "        net.backward(loss_grad)\n",
    "        net.step()\n",
    "        \n",
    "predsRounded = [int(round(x)) for x in preds]\n",
    "\n",
    "print(\"Model predicted: {}\\nactual values: {} \".format(preds, Y.T))\n",
    "print(\"Model predicted: {}\\nactual values: {} \".format(predsRounded, Y.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b43760",
   "metadata": {},
   "source": [
    "<br/><br/>Fantastic! We can clearly see that the model predicts extremely close to 0 and 1 for the correct inputs! This concludes this notebook on back propagation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "037e0af80ddfff16586db0a9bad1571eea055f28bcc51738093bae3ad736c39f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
