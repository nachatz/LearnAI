{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from processor import Processor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lstm import LSTM\n",
    "import itertools\n",
    "\n",
    "train = pd.read_table(\"train.tsv\")\n",
    "valid = pd.read_table(\"valid.tsv\")\n",
    "test = pd.read_table(\"test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Processor.tokenize(train)\n",
    "Processor.tokenize(valid)\n",
    "Processor.tokenize(test)\n",
    "Processor.preprocess_text_data(train)\n",
    "Processor.preprocess_text_data(valid)\n",
    "Processor.preprocess_text_data(test)\n",
    "encodings = Processor.encode(train)\n",
    "label_encodings = encodings[\"label\"]\n",
    "train = shuffle(train)\n",
    "valid = shuffle(valid)\n",
    "test = shuffle(test)\n",
    "training_label = torch.tensor(train[\"label\"])\n",
    "valid_label = torch.tensor(valid[\"label\"])\n",
    "test_label = torch.tensor(test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = list(train[\"text\"])\n",
    "data_valid = list(valid[\"text\"])\n",
    "data_test = list(test[\"text\"])\n",
    "padded = list(zip(*itertools.zip_longest(*data_train, fillvalue=0)))\n",
    "valid_padded = list(zip(*itertools.zip_longest(*data_valid, fillvalue=0)))\n",
    "test_padded = list(zip(*itertools.zip_longest(*data_test, fillvalue=0)))\n",
    "training_data = torch.tensor(padded)\n",
    "valid_data = torch.tensor(valid_padded)\n",
    "test_data = torch.tensor(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom data loaders \n",
    "dataset = TensorDataset(training_data, training_label)\n",
    "train_loader = DataLoader(dataset, batch_size=32)\n",
    "dataset = TensorDataset(valid_data, valid_label)\n",
    "valid_loader = DataLoader(dataset, batch_size=32)\n",
    "dataset = TensorDataset(test_data, test_label)\n",
    "test_loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "lstm = LSTM(1778, 512, 512)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.001)\n",
    "\n",
    "loss_all = 0\n",
    "total_train = 0\n",
    "\n",
    "for epoch in range(4000):\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = lstm(data)\n",
    "\n",
    "        # Compute Loss\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss_all = loss.item() * labels.shape[0]\n",
    "        total_train += labels.shape[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    lstm.eval()\n",
    "    correct = 0\n",
    "    total_valid = valid_label.shape[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = lstm(valid_data)\n",
    "        loss = criterion(y_pred, valid_label)\n",
    "\n",
    "    lstm.train()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Current Epoch: \", epoch)\n",
    "        print(\"Training Loss: \", loss_all / total_train)\n",
    "        print(\"Validation Accuracy: {0:.2f}% \".format(accuracy_score(valid_label, np.argmax(y_pred.data.numpy(), axis=1)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "lstm.eval()\n",
    "correct = 0\n",
    "total = test_label.shape[0]\n",
    "\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = lstm(test_data)\n",
    "    loss = criterion(y_pred.squeeze(0), test_label)\n",
    "    for idx, i in enumerate(y_pred.squeeze(0)):\n",
    "        pred = torch.argmax(i)\n",
    "        preds.append(pred)\n",
    "        if pred == test_label[idx]:\n",
    "            correct += 1\n",
    "\n",
    "# Use the same sentiment_to_id mapping used during training for target_names\n",
    "target_names = {v: k for k, v in label_encodings.items()}\n",
    "\n",
    "print(classification_report(test_label, preds, target_names=target_names))\n",
    "print(matthews_corrcoef(test_label, preds))\n",
    "print(\"Testing accuracy: {:.2f}%\".format(correct / total * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
